import { NextRequest, NextResponse } from 'next/server'
import { extractTextFromPDF, isValidPDF, extractMetadata, splitTextIntoChunks } from '../../../../lib/pdf/pdfReader.js'
import { analyzeDocument, analyzeDocumentInChunks } from '../../../../lib/ai/documentAnalyzer.js'
import { validateAnalysisParams, formatErrorResponse, formatSuccessResponse, calculateTextStats } from '../../../../lib/utils/validation.js'

export const config = {
  api: {
    bodyParser: false, // Importante para upload de arquivos
  },
}

export async function POST(request) {
  try {
    console.log('=== INICIANDO AN√ÅLISE DE PDF ===')
    
    // Parse do FormData
    const formData = await request.formData()
    const file = formData.get('pdf')
    const analysisType = formData.get('analysisType') || 'comprehensive'
    
    console.log('Arquivo recebido:', file?.name, file?.size)
    console.log('Tipo de an√°lise:', analysisType)
    
    // Valida√ß√µes
    if (!file) {
      return NextResponse.json(
        formatErrorResponse('Nenhum arquivo PDF foi enviado', 400),
        { status: 400 }
      )
    }
    
    const analysisValidation = validateAnalysisParams(analysisType)
    if (!analysisValidation.isValid) {
      return NextResponse.json(
        formatErrorResponse(analysisValidation.error, 400),
        { status: 400 }
      )
    }
    
    // Converte arquivo para buffer
    const arrayBuffer = await file.arrayBuffer()
    const buffer = Buffer.from(arrayBuffer)
    
    // Valida se √© um PDF
    if (!isValidPDF(buffer)) {
      return NextResponse.json(
        formatErrorResponse('Arquivo n√£o √© um PDF v√°lido', 400),
        { status: 400 }
      )
    }
    
    console.log('‚úÖ Arquivo PDF v√°lido')
    
    // Extrai texto do PDF
    let pdfData
    try {
      pdfData = await extractTextFromPDF(buffer)
      console.log(`‚úÖ Texto extra√≠do: ${pdfData.wordCount} palavras, ${pdfData.numPages} p√°ginas`)
    } catch (error) {
      console.error('‚ùå Erro na extra√ß√£o do PDF:', error)
      return NextResponse.json(
        formatErrorResponse('Falha ao extrair texto do PDF. Verifique se o arquivo n√£o est√° corrompido.', 422),
        { status: 422 }
      )
    }
    
    // Verifica se h√° texto suficiente
    if (!pdfData.cleanText || pdfData.cleanText.length < 50) {
      return NextResponse.json(
        formatErrorResponse('PDF n√£o cont√©m texto suficiente para an√°lise. Verifique se n√£o √© apenas imagens.', 422),
        { status: 422 }
      )
    }
    
    // Extrai metadados
    const metadata = extractMetadata(pdfData)
    console.log('‚úÖ Metadados extra√≠dos:', metadata.title)
    
    // Calcula estat√≠sticas do texto
    const textStats = calculateTextStats(pdfData.cleanText)
    console.log(`‚úÖ Estat√≠sticas: ${textStats.words} palavras, tempo de leitura: ${textStats.readingTimeMinutes}min`)
    
    // Decide se deve analisar em chunks baseado no tamanho
    const maxTokens = 6000 // Limite conservador para o modelo
    const shouldUseChunks = pdfData.cleanText.length > maxTokens
    
    let analysis
    
    if (shouldUseChunks) {
      console.log('üìÑ Documento grande - analisando em chunks...')
      const chunks = splitTextIntoChunks(pdfData.cleanText, maxTokens)
      console.log(`Dividido em ${chunks.length} chunks`)
      
      analysis = await analyzeDocumentInChunks(chunks, metadata, analysisType)
    } else {
      console.log('üìÑ Documento pequeno - an√°lise direta...')
      analysis = await analyzeDocument(pdfData.cleanText, metadata, analysisType)
    }
    
    console.log('‚úÖ An√°lise conclu√≠da com sucesso')
    
    // Prepara resposta final
    const responseData = {
      fileInfo: {
        name: file.name,
        size: file.size,
        type: file.type,
        pages: pdfData.numPages
      },
      textStats,
      metadata,
      analysis: analysis.analysis,
      analysisType: analysis.analysisType,
      timestamp: analysis.timestamp,
      processingInfo: {
        chunksUsed: shouldUseChunks,
        chunksCount: shouldUseChunks ? analysis.chunksAnalyzed : 1,
        textExtracted: pdfData.wordCount > 0
      }
    }
    
    return NextResponse.json(
      formatSuccessResponse(responseData, 'PDF analisado com sucesso'),
      { status: 200 }
    )
    
  } catch (error) {
    console.error('‚ùå Erro geral na an√°lise:', error)
    
    // Tratamento espec√≠fico de erros
    if (error.message.includes('Azure OpenAI')) {
      return NextResponse.json(
        formatErrorResponse('Servi√ßo de IA temporariamente indispon√≠vel. Tente novamente em alguns minutos.', 503),
        { status: 503 }
      )
    }
    
    if (error.message.includes('rate limit') || error.message.includes('quota')) {
      return NextResponse.json(
        formatErrorResponse('Limite de uso atingido. Tente novamente em alguns minutos.', 429),
        { status: 429 }
      )
    }
    
    return NextResponse.json(
      formatErrorResponse('Erro interno do servidor. Tente novamente mais tarde.', 500),
      { status: 500 }
    )
  }
}

export async function GET() {
  return NextResponse.json({
    message: 'API de an√°lise de PDF',
    endpoints: {
      POST: '/api/pdf/analyze - Envia PDF para an√°lise'
    },
    supportedFormats: ['application/pdf'],
    maxFileSize: '50MB',
    analysisTypes: [
      'comprehensive - An√°lise completa e detalhada',
      'summary - Resumo conciso',
      'academic - An√°lise acad√™mica',
      'business - An√°lise empresarial',
      'educational - An√°lise educacional'
    ]
  })
}
